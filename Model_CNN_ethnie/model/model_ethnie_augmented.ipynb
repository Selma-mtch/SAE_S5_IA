{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèle d'ethnicité UTKFace avec Data Augmentation\n",
    "\n",
    "**Data augmentation appliquée :**\n",
    "- Flip horizontal\n",
    "- Rotation ±15°\n",
    "- Luminosité 0.8-1.2\n",
    "- Zoom ±10%\n",
    "- Décalage ±10%\n",
    "\n",
    "**NON appliqués (fausserait la couleur de peau) :**\n",
    "- Flip vertical\n",
    "- Rotation 90°\n",
    "- Modification de teinte\n",
    "\n",
    "**Dataset :** jangedoo/utkface-new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installation et chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation de kagglehub si nécessaire\n",
    "!pip install -q kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import kagglehub\n",
    "\n",
    "# Télécharger le dataset via kagglehub\n",
    "path = kagglehub.dataset_download(\"jangedoo/utkface-new\")\n",
    "print(f\"Path : {path}\")\n",
    "\n",
    "# Explorer la structure du dataset\n",
    "print(\"\\nContenu du dossier :\")\n",
    "for item in os.listdir(path):\n",
    "    item_path = os.path.join(path, item)\n",
    "    if os.path.isdir(item_path):\n",
    "        print(f\"  [DIR] {item} ({len(os.listdir(item_path))} fichiers)\")\n",
    "    else:\n",
    "        print(f\"  [FILE] {item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trouver automatiquement le dossier contenant les images\n",
    "possible_folders = [\"UTKFace\", \"utkface_aligned_cropped\", \"crop_part1\", \"\"]\n",
    "image_folder = None\n",
    "\n",
    "for folder in possible_folders:\n",
    "    test_path = os.path.join(path, folder) if folder else path\n",
    "    if os.path.exists(test_path):\n",
    "        files = os.listdir(test_path)\n",
    "        jpg_files = [f for f in files if f.endswith(\".jpg\")]\n",
    "        if jpg_files:\n",
    "            image_folder = test_path\n",
    "            print(f\"Dossier d'images trouvé : {image_folder}\")\n",
    "            break\n",
    "\n",
    "if image_folder is None:\n",
    "    raise FileNotFoundError(\"Impossible de trouver le dossier contenant les images UTKFace\")\n",
    "\n",
    "image_files = [f for f in os.listdir(image_folder) if f.endswith(\".jpg\")]\n",
    "print(f\"Nombre de fichiers .jpg trouvés : {len(image_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []\n",
    "\n",
    "for file in image_files:\n",
    "    try:\n",
    "        parts = file.split(\"_\")\n",
    "        age = int(parts[0])\n",
    "        gender = int(parts[1])\n",
    "        try:\n",
    "            race = int(parts[2])\n",
    "        except:\n",
    "            race = 4\n",
    "\n",
    "        img = Image.open(os.path.join(image_folder, file)).convert(\"RGB\").resize((128, 128))\n",
    "        images.append(np.array(img))\n",
    "        labels.append([age, gender, race])\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "print(f\"Images chargées : {len(images)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Imports et préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(f\"TensorFlow version : {tf.__version__}\")\n",
    "print(f\"GPU disponible : {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraire X et y_ethnicity\n",
    "X = images\n",
    "y_ethnicity = labels[:, 2]  # La 3ème colonne = ethnie\n",
    "\n",
    "# Split train/test (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_ethnicity,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Normaliser [0-1]\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "# One-hot encoding (5 classes d'ethnicité)\n",
    "y_train_cat = to_categorical(y_train, num_classes=5)\n",
    "y_test_cat = to_categorical(y_test, num_classes=5)\n",
    "\n",
    "print(f\"X_train : {X_train.shape}\")\n",
    "print(f\"X_test : {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Augmentation avec ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration de l'augmentation pour l'entraînement\n",
    "# Transformations adaptées à la détection d'ethnicité\n",
    "train_datagen = ImageDataGenerator(\n",
    "    horizontal_flip=True,           # Flip horizontal\n",
    "    rotation_range=15,              # Rotation ±15°\n",
    "    brightness_range=[0.8, 1.2],    # Luminosité 0.8-1.2\n",
    "    zoom_range=0.1,                 # Zoom ±10%\n",
    "    width_shift_range=0.1,          # Décalage horizontal ±10%\n",
    "    height_shift_range=0.1,         # Décalage vertical ±10%\n",
    "    fill_mode='nearest',            # Remplissage des pixels manquants\n",
    "    validation_split=0.2            # 20% pour la validation\n",
    ")\n",
    "\n",
    "# Pas d'augmentation pour la validation (juste rescaling déjà fait)\n",
    "val_datagen = ImageDataGenerator(\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Créer les générateurs\nBATCH_SIZE = 64\n\ntrain_generator = train_datagen.flow(\n    X_train, y_train_cat,\n    batch_size=BATCH_SIZE,\n    subset='training',\n    shuffle=True\n)\n\n# Validation sans augmentation (images originales)\nval_generator = val_datagen.flow(\n    X_train, y_train_cat,\n    batch_size=BATCH_SIZE,\n    subset='validation',\n    shuffle=False\n)\n\nprint(f\"Échantillons d'entraînement : {train_generator.n}\")\nprint(f\"Échantillons de validation : {val_generator.n}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Création du modèle CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Entraînement avec Data Augmentation à la volée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Calculer les steps par epoch\n",
    "steps_per_epoch = train_generator.n // BATCH_SIZE\n",
    "validation_steps = val_generator.n // BATCH_SIZE\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=30,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=[early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualisation de l'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axes[0].plot(history.history['loss'], label='Train')\n",
    "axes[0].plot(history.history['val_loss'], label='Validation')\n",
    "axes[0].set_title('Loss')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].plot(history.history['accuracy'], label='Train')\n",
    "axes[1].plot(history.history['val_accuracy'], label='Validation')\n",
    "axes[1].set_title('Accuracy')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Évaluation du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test).argmax(axis=1)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test_cat)\n",
    "print(f\"\\nAccuracy sur le test set : {accuracy*100:.2f}%\")\n",
    "\n",
    "eth_labels = ['Blanc', 'Noir', 'Asiatique', 'Indien', 'Autre']\n",
    "print(\"\\nRapport de classification :\")\n",
    "print(classification_report(y_test, y_pred, target_names=eth_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Matrice de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap='Blues',\n",
    "    xticklabels=eth_labels,\n",
    "    yticklabels=eth_labels\n",
    ")\n",
    "plt.title('Matrice de confusion - Ethnicité (avec Data Augmentation)')\n",
    "plt.xlabel('Prédit')\n",
    "plt.ylabel('Réel')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Sauvegarde du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('ethnicity_model_augmented.keras')\n",
    "print(\"Modèle sauvegardé : ethnicity_model_augmented.keras\")\n",
    "\n",
    "# Télécharger le modèle (Colab)\n",
    "from google.colab import files\n",
    "files.download('ethnicity_model_augmented.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Visualisation des augmentations (Optionnel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def visualize_augmentations(image, datagen, n_examples=6):\n    \"\"\"Visualise les différentes augmentations appliquées à une image.\"\"\"\n    fig, axes = plt.subplots(2, 3, figsize=(10, 7))\n    axes = axes.flatten()\n\n    # Image originale\n    axes[0].imshow(image)\n    axes[0].set_title('Original')\n    axes[0].axis('off')\n\n    # Générer des versions augmentées\n    img_array = image.reshape((1,) + image.shape)\n    aug_iter = datagen.flow(img_array, batch_size=1)\n\n    for i in range(1, n_examples):\n        aug_img = next(aug_iter)[0]\n        aug_img = np.clip(aug_img, 0, 1)  # Évite les valeurs hors [0,1] dues à la luminosité\n        axes[i].imshow(aug_img)\n        axes[i].set_title(f'Augmentation {i}')\n        axes[i].axis('off')\n\n    plt.suptitle('Exemples de Data Augmentation')\n    plt.tight_layout()\n    plt.show()\n\n# Visualiser les augmentations sur une image exemple\nprint(\"Visualisation des augmentations :\")\nvisualize_augmentations(X_train[0], train_datagen)"
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}